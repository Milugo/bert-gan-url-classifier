{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83d\udcca Evaluation & Visualization for BERT-GAN\n",
        "This notebook contains post-training evaluation metrics and visualizations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 1: Import Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, precision_recall_curve\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertTokenizer\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 2: Load model and test data\n",
        "model = tf.keras.models.load_model('../bert_gan_full_model_FINAL.py', compile=False)\n",
        "data = pd.read_csv('../data/data.csv')\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "inputs = tokenizer(data['url'].tolist(), max_length=128, truncation=True, padding='max_length', return_tensors='tf')\n",
        "X = inputs['input_ids'].numpy()\n",
        "y = data['label'].map({'bad': 0, 'good': 1}).values\n",
        "X_test = tf.convert_to_tensor(X, dtype=tf.int32)\n",
        "y_test = tf.convert_to_tensor(y, dtype=tf.float32)\n",
        "z_noise = tf.random.normal((len(X_test), 100))\n",
        "y_probs = model.predict([X_test, z_noise]).flatten()\n",
        "y_preds = (y_probs > 0.5).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 3: Print Evaluation Metrics\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_preds))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_preds))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_probs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 4: Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_preds)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 5: ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
        "plt.plot(fpr, tpr, label='ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# \u2705 Step 6: Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "plt.plot(recall, precision, label='Precision-Recall Curve')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}